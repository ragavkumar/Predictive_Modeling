{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of [Public] Intro To Data Science: Predictive Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ragavkumar/Predictive_Modeling/blob/main/%5BPublic%5D_Intro_To_Data_Science_Predictive_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1QF14cGl13S"
      },
      "source": [
        "# Intro to Data Science: Predictive Modeling\n",
        "## Bank Marketing Data\n",
        "\n",
        "Today, we will be learning the basics of Predictive Modeling by exploring bank marketing data and using it to answer a key question.\n",
        "\n",
        "__Question:__ Is a customer a good candidate for a new product we're offering?\n",
        "\n",
        "__Data Set:__ Information from direct marketing campaigns of a Portuguese banking institution, including:\n",
        "- General customer background information\n",
        "- Customer banking information\n",
        "- Marketing campaign contact information\n",
        "\n",
        "__Goal:__ Use the data from the past to build a predictive model to help us predict who will be good candidates for our marketing initiatives.\n",
        "\n",
        "\n",
        "You will need to add some code to complete this notebook.  Follow along with the instructor to find what code to add.  You will add that where the code says \"\\*\\*\\* ADD CODE HERE\\*\\*\\*\"\n",
        "\n",
        "Have fun and good luck coding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWvn90WamBJN"
      },
      "source": [
        "> To execute a line or block of code, simply click the \"Play\" button on the left side or use the keyboard shortcut \"Shift + Enter\"\n",
        "> When that code block has actually been executed, the blank brackets will change to have a number inside of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw8-EEFC2vvB"
      },
      "source": [
        "## Seed and Target Data\n",
        "## Importing the packages that we'll need\n",
        "\n",
        "One of the things that makes Python **great** for data science is all of the different libraries that exist so we don't have to code them from scratch. Tonight we'll be taking advantage of:\n",
        "- [Numpy](https://numpy.org/) for scientific and mathematical computing\n",
        "- [Pandas](https://pandas.pydata.org/) for data wrangling and analysis\n",
        "- [Sklearn](https://scikit-learn.org/stable/) for all things machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK_k_05xgnce"
      },
      "source": [
        "# Import the appropriate packages\n",
        "***ADD CODE HERE***\n",
        "\n",
        "# machine learning\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
        "\n",
        "# Packages for rendering our tree.\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "import graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2SAlxrr3Ouo"
      },
      "source": [
        "## Import the data\n",
        "Pandas can work with information from all kinds of data sources. Below, we'll import the data we need from a GitHub URL and read it into a Pandas Dataframe using the Pandas [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWQ0tQd7TtB8"
      },
      "source": [
        "# import data from github\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/ephs08kmp/predictive_modeling_workshop/master/bank.csv\",\n",
        "                   sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhy-1w_XxWsg"
      },
      "source": [
        "## Understand the data\n",
        "Exploratory data analysis (EDA) begins with a solid understanding of the data and where you are starting.  This includes starting with the basics of what is in your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UheSZMCouEc4"
      },
      "source": [
        "# Check out the first lines of the data set\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xjbr_a9KcZZ"
      },
      "source": [
        "Quick Notes about some of the variables\n",
        "- Customer Attributes\n",
        "  - **default**: has credit in default? (binary: \"yes\",\"no\")\n",
        "  - **balance**: average yearly balance, in euros (numeric) \n",
        "  - **housing**: has housing loan? (binary: \"yes\",\"no\")\n",
        "  - **loan**: has personal loan? (binary: \"yes\",\"no\")\n",
        "- Related with the last contact of the current campaign:\n",
        "  - **contact**: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
        "  - **day**: last contact day of the month (numeric)\n",
        "  - **month**: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
        "  - **duration**: last contact duration, in seconds (numeric)\n",
        "- Other attributes:\n",
        "  - **campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "  - **pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
        "  - **previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "  - **poutcome**: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
        "- Output variable (desired target AKA \"the thing we're ultimately trying to predict\"):\n",
        "  - **y** - has the client subscribed to our new product? (binary: \"yes\",\"no\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyJPSs4HEWnk"
      },
      "source": [
        "# Checking the size of our data (rows, columns)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm_MKY-RFKKw"
      },
      "source": [
        "# Get a concise summary of the dataset\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBhGCEOqE_sJ"
      },
      "source": [
        "# Understand the basic statistical details of the data set\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULZO_Bgs30pb"
      },
      "source": [
        "## Clean the Data\n",
        "\n",
        "Now that we understand the basics of what's in the data, we need to clean the data before it's ready for modeling.  We won't spend as much time on this today as you would during a full-scale project, but some things you could clean from the data as an extra **challenge**:\n",
        "- Remove duplicate data\n",
        "- Fill in missing data (there isn't any missing data in this dataset)\n",
        "- Identify and clean outliers\n",
        "- Manipulate data\n",
        "\n",
        "> This data is not ready for machine learning because there are both categorical and numerical values, and our model can only interpret numerical values.  We need to turn strings and chars into integers.\n",
        "\n",
        "### Process the Data\n",
        "First, a number of variables are currently a binary of \"yes\" and \"no\", but those values can't be understood by our model.  Let's use the `.map` function to map them to 0 = \"no\" and 1 = \"yes\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r9s8GksOLdK"
      },
      "source": [
        "# Map \"no\" to 0 and \"yes\" to 1\n",
        "yn_map = {'no': 0,\n",
        "          'yes': 1}\n",
        "data['default'] = data['default'].map(yn_map)\n",
        "data['housing'] = data['housing'].map(yn_map)\n",
        "data['loan'] = data['loan'].map(yn_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvZ09KCtPaey"
      },
      "source": [
        "# Check to make sure the change worked \n",
        "# by looking at the first 5 rows of data\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqqnQnL4NJy8"
      },
      "source": [
        "Because we have a number of categorical variables, we need to encode them as numbers.  We can use the pandas [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function to help with this encoding. We will leave job and month out of our model for simplicity.  As a challenge, try adding them back in and see how they impact your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyrHndv1uu2l"
      },
      "source": [
        "# One hot encoding using pandas\n",
        "X = pd.get_dummies(***ADD CODE HERE***)\n",
        "y = data['y']\n",
        "\n",
        "# print out this new formatted data to see what happened\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx4AERYH5O01"
      },
      "source": [
        "Now the columns that were categorical are now numerical.  Feel free to go back and check that these numbers make sense with our original data.\n",
        "\n",
        "Finally, we'll set 20% of the data points from our dataset aside for assessing the model using the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjRy8orW3fof"
      },
      "source": [
        "![](https://docs.splunk.com/images/thumb/3/3b/TrainTest.png/550px-TrainTest.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNAurM-wjBlB"
      },
      "source": [
        "# Creating training and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5280)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXp_kZ-I7KP4"
      },
      "source": [
        "**Now our data is ready for modeling!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEhvqrRH5qjO"
      },
      "source": [
        "### Predictive Modeling\n",
        "#### Decision Trees\n",
        "Decision Trees in classification problems are like flow charts where the model takes the data from the past to figure out the best split points to predict what category the data is in.  \n",
        "\n",
        "[Decision trees](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) are good for unbalanced datasets, but can be prone to overfitting (the model predicts too closely to the training set). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wN5GDvbfwI1"
      },
      "source": [
        "##### Decision Tree Example\n",
        "<div>\n",
        "<img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/08/DecisionTree.png\" width=\"500\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObeMqGQCfnr3"
      },
      "source": [
        "First we will create an empty decision tree, then we will fit the decision tree with all of our marketing data as the inputs, and whether or not the customer subscribed to the new product as the output.  Finally, we will render our tree so we can take a look at our decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubnh0IKoH59F"
      },
      "source": [
        "# Instantiate your model (start up your model) with an empty decision tree\n",
        "clf = tree.DecisionTreeClassifier(max_depth=5,          # Number of nodes (split points)\n",
        "                                  max_features=10,      # Number of features (columns) to consider\n",
        "                                  min_samples_leaf=20,  # Minimum of samples for a leaf (end point)\n",
        "                                  random_state=42)      # Controls randomness for consistency\n",
        "\n",
        "# Fit our decision tree with inputs, target\n",
        "clf_train = clf.fit(***ADD CODE HERE***)\n",
        "\n",
        "# Render our tree.\n",
        "dot_data = tree.export_graphviz(\n",
        "    clf_train, out_file=None,\n",
        "    feature_names=X_train.columns,\n",
        "    class_names=['Not Subscribed', 'Subscribed'],\n",
        "    filled=True\n",
        ")\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4MPn29jhd9Y"
      },
      "source": [
        "> **You be the Data Scientist:** What features look important in making the prediction of whether or not a person will subscribe to a new marketing initiative?\n",
        "\n",
        "While the visual of the decision tree is helpful, tree-based models also provide feature importances, which represent how much each feature (column/variable) impacts the prediction.  Feature importances are values between 0 and 1, with higher values representing features that are more valuable in making predictions.  The feature importance does NOT determine directionality of the prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf8X9fXQdCC1"
      },
      "source": [
        "# Interpreting how the model is making predictions\n",
        "# Decision trees calculate the importance of features \n",
        "# (doesn't speak to directionality)\n",
        "importance = pd.DataFrame(zip(X_train.columns, clf.feature_importances_), \n",
        "                          columns=['Feature', 'Feature Importance'])\n",
        "importance.sort_values(by='Feature Importance', ascending=False)[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7_kAa1ZH95v"
      },
      "source": [
        "### Evaluating Our Model\n",
        "\n",
        "Finally, we'll pass our test set values that we set aside through our model to make predictions using the `.predict()` function.  Then you can check to see the inputs and how they impacted the predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1mQvU3fkPUV"
      },
      "source": [
        "# Running our test set through our model to make predictions\n",
        "y_pred = clf_train.predict(X_test)\n",
        "# Combining our prediction with the base data\n",
        "pred_data = X_test.reset_index().join(pd.DataFrame(zip(y_pred, y_test), \n",
        "                                                   columns=['Predicted Y', 'Actual Y']))\n",
        "# Only display the features used to make predictions for first 10 predictions\n",
        "pred_data[['Predicted Y', 'Actual Y', \n",
        "           'duration', 'poutcome_success', 'contact_unknown',\n",
        "           'marital_married', 'age', 'balance', 'education_tertiary', \n",
        "           'previous', 'marital_single','day']][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG0Qoov1yPM9"
      },
      "source": [
        "Based on the base data, do the predictions match with your decision tree?\n",
        "\n",
        "> **You be the Data Scientist:** What insights can you share about which customers are good targets for new marketing iniatives? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymw7xVzU8i23"
      },
      "source": [
        "Those 10 predictions look good, but how did our model do in predicting the rest of the test set? First, let's take a look at the accuracy of the model using the built-in `.score()` function, which looks at the proportion of predictions that were correct out of all of the predictions.  A score closer to 1 is better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRh66jl0A_dz"
      },
      "source": [
        "# Calculate the accuracy of the model\n",
        "accuracy = clf_train.score(X_test, y_test)\n",
        "print('Accuracy of the test set: ', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVCemTORCI05"
      },
      "source": [
        "That's a pretty good score for an initial model.  Since this is a classification model, let's take a look at how well the model predicted each class (yes/no) using a [confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph9mg_c8H80-"
      },
      "source": [
        "# Create confusion matrix\n",
        "plot_confusion_matrix(clf_train, X_test, y_test, normalize='all', values_format='.2%', cmap='Blues');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uTH3jSQEdQG"
      },
      "source": [
        "We can see that the model did a good job of correctly predicting if someone would not be a good candidate for the new marketing initiative, but not as good of a job of predicting if they would be a good candidate.  This can happen when the training data is unbalanced and contains more of one class than the other.\n",
        "\n",
        "This is also why it's always good to use multiple ways to assess a model to understand the bigger picture of how well your model is making predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3JXx4xsZ5ra"
      },
      "source": [
        "## Take Home Challenges\n",
        "For added practice and to improve your model:\n",
        "- Think about what other factors would help make better predictions about if someone will be a good candidate for a new marketing initiative. Engineer those in your DataFrame in the **Process the Data** section, then run the rest of your code to see how your decision tree changes.  \n",
        "- Change the parameters when you instantiate the model to see how the decision tree changes and if it changes any of your predictions\n",
        "- Add run other classifiers here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSAxTRD6l7OQ"
      },
      "source": [
        "# Keep Learning with Thinkful\n",
        "If you enjoyed today's session and want to take a deeper dive into many of the topics that we covered today like Pandas, SQL, predictive modeling, visualizing your data, and so much more, we'd love to have you join us again!\n",
        "- Check out more of our webinars at [Thinkful Webinars](https://www.thinkful.com/webinars/)\n",
        "- Learn more about the [Data Science Flex Course](https://www.thinkful.com/bootcamp/data-science/flexible/)"
      ]
    }
  ]
}